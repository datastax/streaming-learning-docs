= Getting started with the Starlight for Kafka extension

:description: Learn how to get started using the Starlight for Kafka extension with Pulsar and get hands on with Kafka producer and consumer interacting with a topic.
:title: Getting started with the Starlight for Kafka extension
:navtitle: Kafka

Starlight for Kafka brings the native Apache Kafka protocol support to Apache Pulsar by introducing a Kafka protocol handler on Pulsar brokers. By adding the Starlight for Kafka protocol handler to your existing Pulsar cluster, you can migrate your existing Kafka applications and services to Pulsar without modifying the code.

If source code is your thing, visit the https://github.com/datastax/starlight-for-kafka[project's repo on GitHub^]{external-link-icon}.

== Architecture reference

image:s4k-architecture.png[Starlight for Kafka Architecture]

== Establishing the Kafka protocol handler

Before you can use a Kafka client can interact with your Pulsar cluster, you need the Starlight for Kafka protocol handler installed in the cluster. Installation looks a bit different depending on where your Pulsar cluster is running. Choose the option that best fits your needs.

[tabs]
====
Astra Streaming::
+
--

If you want a working Kafka extension as quickly as possible, this is your best bet. This is also a good option for those that already have a streaming tenant and are looking to extend it.

. Sign in to your Astra account and navigate to your streaming tenant.
+
TIP: Don't have a streaming tenant? Follow our "xref:astra-streaming:getting-started:index.adoc[]" guide.

. Go to the "Connect" tab and choose the "Kafka" option.
+
image:astra-streaming-connect-kafka.png[Astra Streaming connect kafka]

. You will see an "Enable Kafka" button. Click to continue.
+
image:enable-kafka-button.png[Astra Streaming enable kafka]

. A message will let you know of the additions (and restrictions) that come with using Starlight for Kafka.
image:enable-kafka-message.png[Astra Streaming enable kafka message]

. Click the "Enable Kafka" button to confirm your understanding.

Your Astra Streaming tenant is ready for prime time! Continue to the next section of the guide to see it in action.
--
Luna Streaming::
+
--
The Starlight for Kafka extension is included in the `luna-streaming-all` image used to deploy a Luna cluster. The Luna helm chart makes deploying the Kafka extension quite easy. Follow the "xref:luna-streaming:components:starlight-for-kafka.adoc[]" guide to create a simple Pulsar cluster with the Starlight for Kafka extension ready for use.
--
Self Managed::
+
--
Already got your own Pulsar Cluster? Or maybe your using a standalone cluster? Starlight for Kafka can easily be a part of that cluster! Follow the "xref:starlight-for-kafka:installation:starlight-kafka-quickstart.adoc[]" guide.
--
====

== Messaging with Starlight for Kafka

Starlight for Kafka supports quite a few different use cases. With a Pulsar cluster between producers and consumers you can interchange the type of producer and consumer to fit your needs. *The below examples are using an Astra Streaming tenant as the Kafka bootstrap server.* If you are using Luna or self-managed, switch the bootstrap server URL for your own.

=== Retrieve Kafka connection properties in Astra Streaming

While on the "Connect" tab in the Astra Streaming portal, the "kafka" area will provide important connection information. You will need that to create a working Kafka client or using the CLI.

image:kafka-client-settings.png[Astra Streaming kafka settings]

TIP: While reviewing the Kafka connection settings in the Astra portal, if you click the clipboard icon you will get those values as well as a working token to paste in code.

=== Produce and consume a message

[tabs]
====
Kafka CLI::
+
--
Download the latest Kafka dist https://www.apache.org/dyn/closer.cgi?path=/kafka/3.3.1/kafka_2.13-3.3.1.tgz[here^]{external-link-icon}. With the tar ball extracted, the producer and consumer cli's are in the 'bin' folder.

. To get started, let's set a few variables. If you've completed our "xref:astra-streaming:getting-started:index.adoc[Getting started with Astra Streaming]" guide, the below values will be a perfect fit for your existing tenant.
+
[source,shell]
----
SERVICE_URL="<REPLACE_WITH_BOOTSTRAP_SERVER_URL>"
TENANT="<REPLACE_WITH_TENANT_NAME>"
NAMESPACE="<REPLACE_WITH_NAMESPACE>"
TOPIC="<REPLACE_WITH_TOPIC>"
----

. Now let's use those variables to enter in Kafka's producer shell.
+
[source,shell]
----
# cd kafka_2.13-3.3.1
./bin/kafka-console-producer.sh --topic "$TENANT/$NAMESPACE/$TOPIC" --bootstrap-server "$SERVICE_URL"
----

. Type in a super memorable messages and hit 'enter' to send. Press 'Ctrl-C' to exit the shell.
+
[source,shell]
----
> This is my first S4K message.
----

A new message has been produced in the provided tenant/namespace/topic and is ready for consumption.

. Start the Kafka consumer shell.
+
[source,shell]
----
# cd kafka_2.13-3.3.1
./bin/kafka-console-consumer.sh --topic "$TENANT/$NAMESPACE/$TOPIC" --from-beginning --bootstrap-server "$SERVICE_URL"
----

. The consumer should immediately find the new message and output its value.
+
[source,shell]
----
This is my first S4K message.
----

. Press 'Ctrl-C' to exit the consumer shell.

Wow, you did it! Kafka producer and consumer with an Apache Pulsar cluster. How about trying the Java client now?
--
Kafka Client (Java)::
+
--
This example uses maven as the project structure. If you prefer gradle or another, this code should still be a good fit.

TIP: Visit our https://github.com/datastax/astra-streaming-examples[examples repo^]{external-link-icon} to see the complete source of this example.

. Create a new maven project.
+
[source,shell]
----
include::{astra-streaming-examples-repo}/java/starlight-for-kafka/kafka-client/create-project.sh[]
----

. Open the new project in your favorite IDE or text editor and add the Kafka client dependency to "pom.xml".
+
[source,xml]
----
<dependency>
  <groupId>org.apache.kafka</groupId>
  <artifactId>kafka-clients</artifactId>
  <version>3.3.1</version>
</dependency>
----

. Open the file "src/main/java/org/example/App.java" and replace the entire contents with the below code. Notice there are class variables that need replacing. Apply the values previously retrieved in Astra Streaming.
+
[source,java]
----
include::{astra-streaming-examples-repo}/java/starlight-for-kafka/kafka-client/StarlightForKafkaClient/src/main/java/org/example/App.java[tag=init-app]
----
+
NOTE: Don't worry if your editor shows errors, this isn't a complete program... yet.

. Bring in the following code to build the configuration that will be used by both the producer and consumer.
+
[source,java]
----
include::{astra-streaming-examples-repo}/java/starlight-for-kafka/kafka-client/StarlightForKafkaClient/src/main/java/org/example/App.java[tag=build-config]
----

. Now paste the producer code into the file. This is a very simple flow that sends a single message and awaits acknowledgment.
+
[source,java]
----
include::{astra-streaming-examples-repo}/java/starlight-for-kafka/kafka-client/StarlightForKafkaClient/src/main/java/org/example/App.java[tag=build-producer]
----

. Past the consumer code into the file. This creates a basic subscription and retrieves the latest messages on the topic.
+
[source,java]
----
include::{astra-streaming-examples-repo}/java/starlight-for-kafka/kafka-client/StarlightForKafkaClient/src/main/java/org/example/App.java[tag=build-consumer]
----

. Now you should have a complete program. Let's see it in action! Build and run the jar with the following terminal commands.
+
[source,shell]
----
mvn clean package assembly:single
java -jar target/StarlightForKafkaClient-1.0-SNAPSHOT-jar-with-dependencies.jar
----

. If all goes as it should your output will be similar to this:
+
[source,shell]
----
Successfully sent message

Found 1 total record(s)
ConsumerRecord(topic = persistent://my-tenant-007/my-namespace/my-topic, partition = 0, leaderEpoch = null, offset = 22, CreateTime = 1673545962124, serialized key size = 8, serialized value size = 11, headers = RecordHeaders(headers = [], isReadOnly = false), key =   xxxxx, value = Hello World)
----

Congrats! You have just used the Kafka client to send and receive messages in Pulsar. Next stop is the moon!
--
====

The Starlight for Kafka documentation provides more specifics about the below topics and more. Visit those for more detail.

* xref:starlight-for-kafka:operations:starlight-kafka-kstreams.adoc[]
* xref:starlight-for-kafka:operations:starlight-kafka-implementation.adoc[]
* xref:starlight-for-kafka:operations:starlight-kafka-monitor.adoc[Monitoring]
* xref:starlight-for-kafka:operations:starlight-kafka-security.adoc[]